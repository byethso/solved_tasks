{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rebHxfAwmnT",
        "outputId": "afe7e711-52ec-4ebb-81d7-95333724b3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting user-agents\n",
            "  Downloading user_agents-2.2.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting ua-parser>=0.10.0 (from user-agents)\n",
            "  Downloading ua_parser-1.0.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting ua-parser-builtins (from ua-parser>=0.10.0->user-agents)\n",
            "  Downloading ua_parser_builtins-0.18.0.post1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading user_agents-2.2.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading ua_parser-1.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading ua_parser_builtins-0.18.0.post1-py3-none-any.whl (86 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ua-parser-builtins, ua-parser, user-agents\n",
            "Successfully installed ua-parser-1.0.1 ua-parser-builtins-0.18.0.post1 user-agents-2.2.0\n",
            "Первоначальное объединение данных завершено. Размер all_data: (908218, 24)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pathlib import Path\n",
        "!pip install user-agents\n",
        "import user_agents\n",
        "\n",
        "# путь к файлам, я подгружала их сразу в Colab\n",
        "data_path = Path('./')\n",
        "\n",
        "train_labels = pd.read_csv(data_path / 'train_labels.csv', sep=';')\n",
        "#train_df = pd.read_csv(data_path / 'train.csv', sep=';')\n",
        "test_df = pd.read_csv(data_path / 'test.csv', sep=';')\n",
        "referer_vectors = pd.read_csv(data_path / 'referer_vectors.csv', sep=';')\n",
        "geo_info = pd.read_csv(data_path / 'geo_info.csv', sep=';')\n",
        "test_users = pd.read_csv(data_path / 'test_users.csv', sep=';')\n",
        "\n",
        "def merge_csv_files(part1_filename=\"train_part1.csv\", part2_filename=\"train_part2.csv\", sep=';', **kwargs):\n",
        "    try:\n",
        "        df1 = pd.read_csv(part1_filename, sep=sep, **kwargs)\n",
        "        df2 = pd.read_csv(part2_filename, sep=sep, **kwargs)\n",
        "        merged_df = pd.concat([df1, df2], ignore_index=True)\n",
        "        return merged_df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Ошибка: Один или оба CSV-файла не найдены ({part1_filename}, {part2_filename}).\")\n",
        "        return None\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"Ошибка: Один или оба файла CSV пусты или содержат некорректные данные.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Произошла ошибка при объединении CSV-файлов: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "train_df = merge_csv_files(\"train_part1.csv\", \"train_part2.csv\", sep=';')\n",
        "\n",
        "# объединение train и test для создания признаков + добавление флага\n",
        "all_data = pd.concat([train_df.assign(is_test=0), test_df.assign(is_test=1)], ignore_index=True)\n",
        "\n",
        "# Объединение с geo_info и referer_vectors\n",
        "all_data = all_data.merge(geo_info, on='geo_id', how='left')\n",
        "all_data = all_data.merge(referer_vectors, on='referer', how='left')\n",
        "\n",
        "print(\"Первоначальное объединение данных завершено. Размер all_data:\", all_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#БЛОК - ВЫДЕЛЕНИЕ ВРЕМЕННЫХ ПРИЗНАКОВ И ОБРАБОТКА USER_AGENT; выполнение - 7 мин\n",
        "\n",
        "\n",
        "# преобразования request_ts в datetime\n",
        "all_data['request_ts'] = pd.to_datetime(all_data['request_ts'], unit='s')\n",
        "\n",
        "#временные признаки\n",
        "all_data['hour'] = all_data['request_ts'].dt.hour\n",
        "all_data['dayofweek'] = all_data['request_ts'].dt.dayofweek\n",
        "all_data['month'] = all_data['request_ts'].dt.month\n",
        "all_data['is_weekend'] = all_data['dayofweek'].isin([5, 6]).astype(int)\n",
        "\n",
        "\n",
        "#парсинг user_agent, возвращение NaN для отсутсвующих значений и при ошибке\n",
        "def parse_ua(ua_string):\n",
        "    if pd.isna(ua_string):\n",
        "        return [np.nan] * 5\n",
        "    try:\n",
        "        ua = user_agents.parse(ua_string)\n",
        "        return [ua.os.family, ua.browser.family, ua.device.family, ua.is_mobile, ua.is_tablet]\n",
        "    except Exception as e:\n",
        "        return [np.nan] * 5\n",
        "\n",
        "\n",
        "# Применяем функцию И создаем новые колонки\n",
        "all_data[['os_family', 'browser_family', 'device_family', 'is_mobile', 'is_tablet']] = \\\n",
        "    all_data['user_agent'].apply(lambda x: pd.Series(parse_ua(x)))\n",
        "\n",
        "# преобразование булевы признаки is_mobile и is_tablet в числовые (0 или 1)\n",
        "all_data['is_mobile'] = all_data['is_mobile'].astype(float).fillna(0)\n",
        "all_data['is_tablet'] = all_data['is_tablet'].astype(float).fillna(0)"
      ],
      "metadata": {
        "id": "JTNomYkc3szP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# БЛОК - ПРОДОЛЖЕНИЕ ВЫДЕЛЕНИЯ ПРИЗНАКОВ; выполнение - 9 мин\n",
        "\n",
        "#обработка referer\n",
        "def extract_domain_path(referer_url):\n",
        "    if pd.isna(referer_url) or not isinstance(referer_url, str):\n",
        "        return np.nan, np.nan\n",
        "    parts = referer_url.split('/')\n",
        "    if len(parts) > 2: # https://domain/path -> parts[2] = domain, parts[3] = path\n",
        "        domain = parts[2]\n",
        "        path = parts[3] if len(parts) > 3 else np.nan\n",
        "        return domain, path\n",
        "    return np.nan, np.nan\n",
        "\n",
        "all_data[['domain_hashed', 'path_hashed']] = all_data['referer'].apply(lambda x: pd.Series(extract_domain_path(x)))\n",
        "\n",
        "\n",
        "\n",
        "#все категориальные столбцы\n",
        "categorical_cols_to_encode = [\n",
        "    'geo_id',\n",
        "    'country_id',\n",
        "    'region_id',\n",
        "    'timezone',\n",
        "    'os_family',\n",
        "    'browser_family',\n",
        "    'device_family',\n",
        "    'domain_hashed',\n",
        "    'path_hashed'\n",
        "]\n",
        "\n",
        "for col in categorical_cols_to_encode:\n",
        "    if col in all_data.columns:\n",
        "        all_data[col] = all_data[col].fillna(f'MISSING_{col}')\n",
        "\n",
        "\n",
        "        # Создаем новый столбец с закодированными значениями\n",
        "        le = LabelEncoder()\n",
        "        if all_data[col].nunique() > 0: # Проверяем, есть ли уникальные значения для кодирования\n",
        "            all_data[f'{col}_encoded'] = le.fit_transform(all_data[col])\n",
        "        else:\n",
        "            all_data[f'{col}_encoded'] = -1  #если уникальных нет, то кодируем -1\n",
        "    else:\n",
        "        print(f\"Внимание: Колонка '{col}' не найдена в all_data. Пропускаем кодирование.\")\n",
        "\n",
        "\n",
        "\n",
        "#Агрегированные признаки на уровне пользователя\n",
        "user_features = all_data.groupby('user_id').agg(\n",
        "    count_requests=('request_ts', 'size'), #общее кол-во запросов\n",
        "    min_ts=('request_ts', 'min'), #мин время запроса\n",
        "    max_ts=('request_ts', 'max'), #макс время запроса\n",
        "    nunique_geo_id=('geo_id', 'nunique'), #кол-во уникальных geo_id\n",
        "    nunique_referer=('referer', 'nunique'),\n",
        "    nunique_domain_hashed=('domain_hashed', 'nunique'),\n",
        "    nunique_path_hashed=('path_hashed', 'nunique'),\n",
        "    nunique_os_family=('os_family', 'nunique'),\n",
        "    nunique_browser_family=('browser_family', 'nunique'),\n",
        "    #среднее и стандартное отклонение referer_vectors\n",
        "    **{f'mean_comp{i}': (f'component{i}', 'mean') for i in range(10)},\n",
        "    **{f'std_comp{i}': (f'component{i}', 'std') for i in range(10)},\n",
        "    #мода для категориальных, среднее для булевых из user_agent\n",
        "    most_frequent_os=('os_family_encoded', lambda x: x.mode()[0] if not x.mode().empty else -1), # -1  для неизвестного\n",
        "    most_frequent_browser=('browser_family_encoded', lambda x: x.mode()[0] if not x.mode().empty else -1),\n",
        "    avg_is_mobile=('is_mobile', 'mean'),\n",
        "    avg_is_tablet=('is_tablet', 'mean'),\n",
        ").reset_index()\n",
        "\n",
        "#продолжительность активности пользователя в секундах\n",
        "user_features['user_activity_span_seconds'] = (user_features['max_ts'] - user_features['min_ts']).dt.total_seconds()\n",
        "user_features.drop(columns=['min_ts', 'max_ts'], inplace=True)\n",
        "\n",
        "\n",
        "# Присоединение пола (target) к обучающим пользователям\n",
        "train_merged = train_labels.merge(user_features, on='user_id', how='left')\n",
        "\n",
        "#nестовый датасет c присоединенными признаками\n",
        "test_merged = test_users.merge(user_features, on='user_id', how='left')\n",
        "\n",
        "print(\"Генерация агрегированных признаков завершена.\")\n",
        "print(\"Размер train_merged:\", train_merged.shape)\n",
        "print(\"Размер test_merged:\", test_merged.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH3bexg3wvmI",
        "outputId": "62da5917-0f24-42cb-9cf2-c335600be523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Внимание: Колонка 'timezone' не найдена в all_data. Пропускаем кодирование.\n",
            "Генерация агрегированных признаков завершена.\n",
            "Размер train_merged: (500000, 34)\n",
            "Размер test_merged: (85000, 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#БЛОК - ПОДГОТОВКА И ОБУЧЕНИЕ; выполнение - 14 минут\n",
        "\n",
        "#x - все кроме user_id и target, y - target\n",
        "X = train_merged.drop(columns=['user_id', 'target'])\n",
        "y = train_merged['target']\n",
        "\n",
        "X_test_final = test_merged.drop(columns=['user_id'])\n",
        "\n",
        "#для LightGBM выравниваем число признаков\n",
        "common_cols = list(set(X.columns) & set(X_test_final.columns))\n",
        "X = X[common_cols]\n",
        "X_test_final = X_test_final[common_cols]\n",
        "\n",
        "#список категориальных признаков\n",
        "categorical_features_for_lgbm = []\n",
        "for col in X.columns:\n",
        "    #просмотр закодированных категориальных признаков\n",
        "    if col.endswith('_encoded'):\n",
        "        X[col] = X[col].astype('category')\n",
        "        if col in X_test_final.columns: #проверка на существование в тестовом наборе\n",
        "            X_test_final[col] = X_test_final[col].astype('category')\n",
        "        categorical_features_for_lgbm.append(col)\n",
        "\n",
        "    elif X[col].dtype == 'bool':\n",
        "        X[col] = X[col].astype('category')\n",
        "        if col in X_test_final.columns:\n",
        "            X_test_final[col] = X_test_final[col].astype('category')\n",
        "        categorical_features_for_lgbm.append(col)\n",
        "    elif pd.api.types.is_numeric_dtype(X[col]):\n",
        "        #числовые признаки пропускаем, не делаем категориальными\n",
        "        pass\n",
        "    else:\n",
        "        #для прочих типов, если появятся\n",
        "        try:\n",
        "            X[col] = X[col].astype('category')\n",
        "            if col in X_test_final.columns:\n",
        "                X_test_final[col] = X_test_final[col].astype('category')\n",
        "            categorical_features_for_lgbm.append(col)\n",
        "            print(f\"Преобразована колонка '{col}' к типу 'category' (была {X[col].dtype}).\")\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка при преобразовании '{col}' в 'category': {e}\")\n",
        "            pass\n",
        "\n",
        "print(f\"Количество признаков для модели: {len(X.columns)}\")\n",
        "\n",
        "\n",
        "NFOLDS = 5 #кол-во фолдов для кросс-валидации\n",
        "folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42) #баланс разделения классов\n",
        "oof_preds = np.zeros(X.shape[0]) #предсказания для оценки на тренировочной выборке\n",
        "sub_preds = np.zeros(X_test_final.shape[0]) #предсказания на тестовой выборке\n",
        "\n",
        "print(f\"Начинаем обучение LightGBM с {NFOLDS}-кратной StratifiedKFold валидацией...\")\n",
        "\n",
        "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
        "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "    X_val, y_val = X.iloc[valid_idx], y.iloc[valid_idx]\n",
        "\n",
        "    lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
        "                                 metric='auc',\n",
        "                                 n_estimators=2000,\n",
        "                                 learning_rate=0.01,\n",
        "                                 num_leaves=64,\n",
        "                                 max_depth=-1,\n",
        "                                 min_child_samples=20,\n",
        "                                 subsample=0.7,\n",
        "                                 colsample_bytree=0.7,\n",
        "                                 random_state=42,\n",
        "                                 n_jobs=-1,\n",
        "                                 is_unbalance=True\n",
        "                                )\n",
        "\n",
        "    lgb_clf.fit(X_train, y_train,\n",
        "                eval_set=[(X_val, y_val)],\n",
        "                eval_metric='auc',\n",
        "                callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)],\n",
        "                categorical_feature=[col for col in categorical_features_for_lgbm if col in X_train.columns]\n",
        "               )\n",
        "\n",
        "    oof_preds[valid_idx] = lgb_clf.predict_proba(X_val)[:, 1]\n",
        "    sub_preds += lgb_clf.predict_proba(X_test_final)[:, 1] / folds.n_splits\n",
        "\n",
        "    print(f\"Fold {n_fold+1} завершен. AUC на валидации: {roc_auc_score(y_val, oof_preds[valid_idx]):.4f}\")\n",
        "\n",
        "\n",
        "cv_auc_score = roc_auc_score(y, oof_preds)\n",
        "print(f\"\\nСредний CV AUC на всех фолдах: {cv_auc_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhEoLHyo9vQz",
        "outputId": "ffac3546-a95f-4496-939c-84557924a97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество признаков для модели: 32\n",
            "Начинаем обучение LightGBM с 5-кратной StratifiedKFold валидацией...\n",
            "[LightGBM] [Info] Number of positive: 190784, number of negative: 209216\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.322055 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5423\n",
            "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 32\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.476960 -> initscore=-0.092225\n",
            "[LightGBM] [Info] Start training from score -0.092225\n",
            "Fold 1 завершен. AUC на валидации: 0.8839\n",
            "[LightGBM] [Info] Number of positive: 190784, number of negative: 209216\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122279 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5425\n",
            "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 32\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.476960 -> initscore=-0.092225\n",
            "[LightGBM] [Info] Start training from score -0.092225\n",
            "Fold 2 завершен. AUC на валидации: 0.8817\n",
            "[LightGBM] [Info] Number of positive: 190784, number of negative: 209216\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165810 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5429\n",
            "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 32\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.476960 -> initscore=-0.092225\n",
            "[LightGBM] [Info] Start training from score -0.092225\n",
            "Fold 3 завершен. AUC на валидации: 0.8837\n",
            "[LightGBM] [Info] Number of positive: 190784, number of negative: 209216\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122385 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5427\n",
            "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 32\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.476960 -> initscore=-0.092225\n",
            "[LightGBM] [Info] Start training from score -0.092225\n",
            "Fold 4 завершен. AUC на валидации: 0.8826\n",
            "[LightGBM] [Info] Number of positive: 190784, number of negative: 209216\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120109 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5425\n",
            "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 32\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.476960 -> initscore=-0.092225\n",
            "[LightGBM] [Info] Start training from score -0.092225\n",
            "Fold 5 завершен. AUC на валидации: 0.8824\n",
            "\n",
            "Средний CV AUC на всех фолдах: 0.8828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#сохранение последней модели\n",
        "model_filename = 'gender_prediction_model.joblib'\n",
        "joblib.dump(lgb_clf, model_filename)\n",
        "print(f\"\\nМодель сохранена в '{model_filename}'\")\n",
        "\n",
        "\n",
        "#приведение к int для получения чистых 0 и 1, порог 0,5\n",
        "final_predictions = (sub_preds >= 0.5).astype(int)\n",
        "\n",
        "test_result = pd.DataFrame({'user_id': test_users['user_id'], 'target': final_predictions})\n",
        "test_result.to_csv('test_result.csv', index=False, sep=';')\n",
        "\n",
        "print(\"Файл test_result.csv успешно создан.\")\n",
        "print(\"Предсказания сохранены в 'test_result.csv'.\")\n",
        "print(\"Готово!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTkOMmaVzgE0",
        "outputId": "05c933aa-cb13-4882-a083-9bbf6e988f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Модель сохранена в 'gender_prediction_model.joblib'\n",
            "Файл test_result.csv успешно создан.\n",
            "Предсказания сохранены в 'test_result.csv'.\n",
            "Готово!\n"
          ]
        }
      ]
    }
  ]
}